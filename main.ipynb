{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import sys\n",
    "sys.path.append('/scratch/ys5hd/CPET/code/')\n",
    "\n",
    "import os\n",
    "import re\n",
    "import cv2\n",
    "import copy\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from model.maxpoolcnn import *\n",
    "# from model.avgpoolcnn import *\n",
    "\n",
    "from functools import reduce\n",
    "from pyts.image import GramianAngularField, MarkovTransitionField\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "torch.cuda.manual_seed_all(0)\n",
    "np.random.seed(0)\n",
    "random.seed(0)\n",
    "\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATAPATH\n",
    "# Unzip wafer.zip and add PATH here\n",
    "PATH = \"/project/GutIntelligenceLab/ys5hd/CPET/wafer 2/\" \n",
    "selected_cols = ['8', '15', '7', '12', '11', '6']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['abnormal', 'README', 'normal', '.DS_Store']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read Data Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_wafer(path=PATH):\n",
    "    \n",
    "    list_of_df = []\n",
    "    series_name = list(set([x.split('.')[-1] for x in os.listdir(PATH+'normal')]))\n",
    "    for file_type in ['abnormal', 'normal']:\n",
    "        for fname in list(set([x.split('.')[0] for x in os.listdir(PATH+file_type)])):\n",
    "            dic = {}\n",
    "            label = ''\n",
    "            for nm in series_name:\n",
    "                df_inst = pd.read_csv(PATH+file_type+'/'+fname+'.'+nm, delimiter = \"\\t\", header=None)\n",
    "                if df_inst.shape[1]>1:\n",
    "                    #dic[nm] = minmax_scale(df_inst[1])\n",
    "                    dic[nm] = df_inst[1]\n",
    "                else:\n",
    "                    label = df_inst[0].values[0]\n",
    "            df_inst = pd.DataFrame(dic)\n",
    "            df_inst['label'] = label\n",
    "            df_inst['id'] = fname\n",
    "            df_inst = df_inst.reset_index()\n",
    "            list_of_df.append(df_inst)\n",
    "\n",
    "    df_agg = pd.concat(list_of_df)    \n",
    "\n",
    "    df_agg['target'] = df_agg['label'].apply(lambda x: 0 if x=='#FAULT=normal' else 1)\n",
    "    label_map = dict(zip(df_agg[['id', 'target']].drop_duplicates().id, df_agg[['id', 'target']].drop_duplicates().target))    \n",
    "    \n",
    "    return df_agg, label_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_agg, label_map = read_wafer(PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_gram(x, image_size=104, method='difference'):\n",
    "    ''' \n",
    "    Run Gramian Angular Field, recommended to keep image size equivalent to minimum length of time series\n",
    "    '''\n",
    "    gasf = GramianAngularField(image_size=image_size)\n",
    "    X_gasf = gasf.fit_transform(np.array([x]))\n",
    "    return X_gasf[0]\n",
    "\n",
    "def run_mtf(x):\n",
    "    ''' \n",
    "    Run Markov Transition Field, recommended to keep image size equivalent to minimum length of time series\n",
    "    '''\n",
    "    mtf = MarkovTransitionField(image_size=104)\n",
    "    X_mtf = mtf.fit_transform(np.array([x]))\n",
    "    return X_mtf[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encode Time Series as Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list = []\n",
    "for col in selected_cols:    \n",
    "    df_list.append(df_agg.groupby('id')[col].apply(lambda x: run_mtf(x)).reset_index())\n",
    "    \n",
    "df_merged = reduce(lambda  left,right: pd.merge(left,right,on=['id'],\n",
    "                                            how='outer'), df_list)  \n",
    "df = df_merged.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>8</th>\n",
       "      <th>15</th>\n",
       "      <th>7</th>\n",
       "      <th>12</th>\n",
       "      <th>11</th>\n",
       "      <th>6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1549_01</td>\n",
       "      <td>[[0.8823529411764706, 0.8823529411764706, 0.88...</td>\n",
       "      <td>[[0.6666666666666666, 0.6666666666666666, 0.29...</td>\n",
       "      <td>[[0.8148148148148148, 0.8148148148148148, 0.81...</td>\n",
       "      <td>[[0.9459459459459459, 0.9459459459459459, 0.94...</td>\n",
       "      <td>[[0.9428571428571428, 0.9428571428571428, 0.94...</td>\n",
       "      <td>[[0.8787878787878788, 0.8787878787878788, 0.87...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1549_02</td>\n",
       "      <td>[[0.8888888888888888, 0.8888888888888888, 0.88...</td>\n",
       "      <td>[[0.7435897435897436, 0.7435897435897436, 0.74...</td>\n",
       "      <td>[[0.7727272727272727, 0.7727272727272727, 0.77...</td>\n",
       "      <td>[[0.9523809523809523, 0.9523809523809523, 0.95...</td>\n",
       "      <td>[[0.9512195121951219, 0.9512195121951219, 0.95...</td>\n",
       "      <td>[[0.9523809523809523, 0.9523809523809523, 0.95...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1549_04</td>\n",
       "      <td>[[0.8888888888888888, 0.8888888888888888, 0.88...</td>\n",
       "      <td>[[0.6086956521739131, 0.6086956521739131, 0.30...</td>\n",
       "      <td>[[0.8378378378378378, 0.8378378378378378, 0.83...</td>\n",
       "      <td>[[0.9534883720930233, 0.9534883720930233, 0.95...</td>\n",
       "      <td>[[0.9523809523809523, 0.9523809523809523, 0.95...</td>\n",
       "      <td>[[0.8333333333333334, 0.8333333333333334, 0.83...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1549_06</td>\n",
       "      <td>[[0.9130434782608695, 0.9130434782608695, 0.91...</td>\n",
       "      <td>[[0.6666666666666666, 0.25925925925925924, 0.2...</td>\n",
       "      <td>[[0.8333333333333334, 0.8333333333333334, 0.06...</td>\n",
       "      <td>[[0.9545454545454546, 0.9545454545454546, 0.95...</td>\n",
       "      <td>[[0.9534883720930233, 0.9534883720930233, 0.95...</td>\n",
       "      <td>[[0.875, 0.875, 0.875, 0.875, 0.875, 0.875, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1549_07</td>\n",
       "      <td>[[0.8888888888888888, 0.8888888888888888, 0.88...</td>\n",
       "      <td>[[0.6153846153846154, 0.6153846153846154, 0.46...</td>\n",
       "      <td>[[0.9183673469387755, 0.9183673469387755, 0.91...</td>\n",
       "      <td>[[0.9523809523809523, 0.9523809523809523, 0.95...</td>\n",
       "      <td>[[0.9512195121951219, 0.9512195121951219, 0.95...</td>\n",
       "      <td>[[0.95, 0.95, 0.95, 0.95, 0.95, 0.95, 0.95, 0....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                                  8  \\\n",
       "0  1549_01  [[0.8823529411764706, 0.8823529411764706, 0.88...   \n",
       "1  1549_02  [[0.8888888888888888, 0.8888888888888888, 0.88...   \n",
       "2  1549_04  [[0.8888888888888888, 0.8888888888888888, 0.88...   \n",
       "3  1549_06  [[0.9130434782608695, 0.9130434782608695, 0.91...   \n",
       "4  1549_07  [[0.8888888888888888, 0.8888888888888888, 0.88...   \n",
       "\n",
       "                                                  15  \\\n",
       "0  [[0.6666666666666666, 0.6666666666666666, 0.29...   \n",
       "1  [[0.7435897435897436, 0.7435897435897436, 0.74...   \n",
       "2  [[0.6086956521739131, 0.6086956521739131, 0.30...   \n",
       "3  [[0.6666666666666666, 0.25925925925925924, 0.2...   \n",
       "4  [[0.6153846153846154, 0.6153846153846154, 0.46...   \n",
       "\n",
       "                                                   7  \\\n",
       "0  [[0.8148148148148148, 0.8148148148148148, 0.81...   \n",
       "1  [[0.7727272727272727, 0.7727272727272727, 0.77...   \n",
       "2  [[0.8378378378378378, 0.8378378378378378, 0.83...   \n",
       "3  [[0.8333333333333334, 0.8333333333333334, 0.06...   \n",
       "4  [[0.9183673469387755, 0.9183673469387755, 0.91...   \n",
       "\n",
       "                                                  12  \\\n",
       "0  [[0.9459459459459459, 0.9459459459459459, 0.94...   \n",
       "1  [[0.9523809523809523, 0.9523809523809523, 0.95...   \n",
       "2  [[0.9534883720930233, 0.9534883720930233, 0.95...   \n",
       "3  [[0.9545454545454546, 0.9545454545454546, 0.95...   \n",
       "4  [[0.9523809523809523, 0.9523809523809523, 0.95...   \n",
       "\n",
       "                                                  11  \\\n",
       "0  [[0.9428571428571428, 0.9428571428571428, 0.94...   \n",
       "1  [[0.9512195121951219, 0.9512195121951219, 0.95...   \n",
       "2  [[0.9523809523809523, 0.9523809523809523, 0.95...   \n",
       "3  [[0.9534883720930233, 0.9534883720930233, 0.95...   \n",
       "4  [[0.9512195121951219, 0.9512195121951219, 0.95...   \n",
       "\n",
       "                                                   6  \n",
       "0  [[0.8787878787878788, 0.8787878787878788, 0.87...  \n",
       "1  [[0.9523809523809523, 0.9523809523809523, 0.95...  \n",
       "2  [[0.8333333333333334, 0.8333333333333334, 0.83...  \n",
       "3  [[0.875, 0.875, 0.875, 0.875, 0.875, 0.875, 0....  \n",
       "4  [[0.95, 0.95, 0.95, 0.95, 0.95, 0.95, 0.95, 0....  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GAFloader(Dataset):\n",
    "    def __init__(self, df, label_map, stackwise=True):\n",
    "        self.df = df\n",
    "        self.id_list = list(df['id'].unique())\n",
    "        self.label_map = label_map\n",
    "        self.stackwise = stackwise\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.id_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        id_instance = self.id_list[idx]\n",
    "        if self.stackwise:\n",
    "            inp = torch.tensor(np.vstack(self.df.loc[idx, selected_cols].values)[None])\n",
    "        else:\n",
    "            inp = torch.tensor(np.stack(self.df.loc[idx, selected_cols].values))\n",
    "        label = self.label_map[id_instance]\n",
    "        return inp, label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stratfied KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df_agg[['id', 'target']].drop_duplicates().reset_index(drop=True)['id']\n",
    "y = df_agg[['id', 'target']].drop_duplicates().reset_index(drop=True)['target']\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5)\n",
    "skf.get_n_splits(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_split = []\n",
    "for i, (train_index, test_index) in enumerate(skf.split(X, y)):\n",
    "    list_of_split.append(pd.DataFrame({'id': X[test_index], 'label': y[test_index], 'split': [i]*len(test_index)}))\n",
    "    \n",
    "df_split = pd.concat(list_of_split)    \n",
    "df = pd.merge(df, df_split, on='id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 1/5 [02:17<09:10, 137.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of Validation Data: 239\n",
      "Accuracy for fold: 0 - 0.9916317991631799\n",
      "Epoch: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|████      | 2/5 [04:36<06:54, 138.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of Validation Data: 239\n",
      "Accuracy for fold: 1 - 0.9874476987447699\n",
      "Epoch: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|██████    | 3/5 [07:09<04:44, 142.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of Validation Data: 239\n",
      "Accuracy for fold: 2 - 0.9916317991631799\n",
      "Epoch: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|████████  | 4/5 [09:30<02:22, 142.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of Validation Data: 239\n",
      "Accuracy for fold: 3 - 0.99581589958159\n",
      "Epoch: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [11:41<00:00, 140.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of Validation Data: 238\n",
      "Accuracy for fold: 4 - 0.9957983193277311\n",
      "Epoch: 0\n",
      "Validation Accuracy: 99.2462311557789%\n",
      "Error Rate: 0.007537688442211032%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "stackwise = False\n",
    "NUM_RUNS = 20\n",
    "NUM_EPOCHS = 100\n",
    "\n",
    "vt_list = []\n",
    "for _ in range(NUM_RUNS):\n",
    "\n",
    "    attn_df_list = []\n",
    "    val_acc_tracker = []\n",
    "    best_epoch = -1\n",
    "\n",
    "    for k in tqdm(range(5)):    \n",
    "        val_pat = df.loc[df['split']==k]['id'].tolist()\n",
    "\n",
    "        train_ds = GAFloader(df.loc[df['split']!=k].reset_index(drop=True), label_map, stackwise)\n",
    "        train_dl = DataLoader(train_ds, batch_size=1, shuffle=True)\n",
    "\n",
    "        val_ds = GAFloader(df.loc[df['split']==k].reset_index(drop=True), label_map, stackwise)\n",
    "        val_dl = DataLoader(val_ds, batch_size=1, shuffle=True)\n",
    "\n",
    "        dl = {'train': train_dl, 'val': val_dl}\n",
    "        d_size = {'train': len(train_ds), 'val': len(val_ds)}\n",
    "\n",
    "        # Net\n",
    "        if stackwise:\n",
    "            net = GafStackNet().to(device)\n",
    "        else:\n",
    "            net = GafAttnNet(mean=False).to(device)\n",
    "\n",
    "        # create your optimizer\n",
    "        # optimizer = optim.SGD(net.parameters(), lr=0.01)    \n",
    "        optimizer = optim.Adam(net.parameters(), lr=0.0023) #lr=1e-4)\n",
    "\n",
    "        # Loss\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "        # Training\n",
    "        best_val_acc = 0\n",
    "        loss_tracker = []\n",
    "        for epoch in range(NUM_EPOCHS):\n",
    "            for phase in ['train', 'val']:\n",
    "                running_corrects = 0.0\n",
    "                for i, (im, label) in enumerate(dl[phase]):\n",
    "                    im = im.float().to(device)\n",
    "                    label = label.to(device)\n",
    "\n",
    "                    optimizer.zero_grad()\n",
    "\n",
    "                    if phase == 'train':\n",
    "                        net.train()\n",
    "                    else:\n",
    "                        net.eval()\n",
    "\n",
    "                    output, _ = net(im)\n",
    "                    _, preds = torch.max(output, 1)\n",
    "                    loss = criterion(output, label)\n",
    "\n",
    "                    running_corrects += torch.sum(preds == label.data)            \n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                    loss_tracker.append(loss.item())\n",
    "#                 print('Phase: {}, Epoch: {}, Loss: {}, Acc: {}'.format(phase, epoch+1,\\\n",
    "#                                                                        np.mean(loss_tracker), \\\n",
    "#                                                                        running_corrects/d_size[phase]))            \n",
    "                loss_tracker = []\n",
    "                if phase == 'val' and (running_corrects/d_size[phase]) > best_val_acc:\n",
    "                    best_val_acc = running_corrects/d_size[phase]\n",
    "                    best_model_wts = copy.deepcopy(net.state_dict())\n",
    "                    best_epoch = epoch\n",
    "\n",
    "        net.load_state_dict(best_model_wts)\n",
    "\n",
    "        pred = []\n",
    "        actual = []\n",
    "        attn_list = []\n",
    "        with torch.no_grad():\n",
    "            for i, (im, label) in enumerate(val_dl):\n",
    "                output, attn_wt = net(im.float().to(device))\n",
    "                pred += list(torch.max(output, axis=1)[1].cpu().numpy())\n",
    "                actual += list(label.numpy())\n",
    "                if not stackwise:\n",
    "                    attn_list.append(list(attn_wt.detach().cpu().numpy()))            \n",
    "\n",
    "        if not stackwise:\n",
    "            temp = pd.DataFrame(attn_list, columns=selected_cols)\n",
    "            temp['pred'] = pred\n",
    "            temp['actual'] = actual\n",
    "            attn_df_list.append(temp)\n",
    "\n",
    "        print('Length of Validation Data: {}'.format(len(pred)))\n",
    "        print('Accuracy for fold: {} - {}'.format(k, sum(np.array(pred) == np.array(actual))/len(pred)))\n",
    "        print('Epoch: {}'.format(best_epoch))\n",
    "        val_acc_tracker.append(sum(np.array(pred) == np.array(actual)))\n",
    "\n",
    "    print('Validation Accuracy: {}%'.format((np.sum(val_acc_tracker)/df.shape[0])*100))\n",
    "    print('Error Rate: {}%'.format(1-(np.sum(val_acc_tracker)/df.shape[0])))\n",
    "    vt_list.append((np.sum(val_acc_tracker)/df.shape[0])*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean/Std Accuracy: 99.2462311557789 (0.0)\n"
     ]
    }
   ],
   "source": [
    "print('Mean/Std Accuracy: {} ({})'.format(np.mean(vt_list), np.std(vt_list)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attention Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>8</th>\n",
       "      <th>15</th>\n",
       "      <th>7</th>\n",
       "      <th>12</th>\n",
       "      <th>11</th>\n",
       "      <th>6</th>\n",
       "      <th>pred</th>\n",
       "      <th>actual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.001568</td>\n",
       "      <td>5.263753e-07</td>\n",
       "      <td>0.000383</td>\n",
       "      <td>0.998025</td>\n",
       "      <td>8.182898e-07</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.059991</td>\n",
       "      <td>4.555024e-07</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.939987</td>\n",
       "      <td>2.114229e-06</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.700343</td>\n",
       "      <td>0.000787</td>\n",
       "      <td>1.129749e-03</td>\n",
       "      <td>0.018550</td>\n",
       "      <td>0.166957</td>\n",
       "      <td>1.122321e-01</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.050836</td>\n",
       "      <td>9.274229e-07</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>0.949125</td>\n",
       "      <td>2.960254e-06</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.275377</td>\n",
       "      <td>9.859888e-07</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.724605</td>\n",
       "      <td>6.473377e-08</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          8        15             7        12        11             6  pred  \\\n",
       "0  0.000022  0.001568  5.263753e-07  0.000383  0.998025  8.182898e-07     0   \n",
       "1  0.000013  0.059991  4.555024e-07  0.000005  0.939987  2.114229e-06     0   \n",
       "2  0.700343  0.000787  1.129749e-03  0.018550  0.166957  1.122321e-01     1   \n",
       "3  0.000003  0.050836  9.274229e-07  0.000033  0.949125  2.960254e-06     0   \n",
       "4  0.000002  0.275377  9.859888e-07  0.000016  0.724605  6.473377e-08     0   \n",
       "\n",
       "   actual  \n",
       "0       0  \n",
       "1       0  \n",
       "2       1  \n",
       "3       0  \n",
       "4       0  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Picked up from latest epoch \n",
    "# Update code to track for all the epochs\n",
    "pd.concat(attn_df_list).head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch 1.5.1 Py3.7",
   "language": "python",
   "name": "pytorch-1.5.1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
